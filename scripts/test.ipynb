{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a66ad6",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'compress_system1/pack_mol.data'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 63\u001b[0m\n\u001b[1;32m     60\u001b[0m logger \u001b[38;5;241m=\u001b[39m logger\u001b[38;5;241m.\u001b[39mbind(name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCompress Dynamics (for ReaxFF)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     62\u001b[0m \u001b[38;5;66;03m# step 1: built ASE atoms\u001b[39;00m\n\u001b[0;32m---> 63\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mflag\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/pack_mol.data\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m     64\u001b[0m     data \u001b[38;5;241m=\u001b[39m load_lammps_data_0(f\u001b[38;5;241m.\u001b[39mread())\n\u001b[1;32m     65\u001b[0m     data \u001b[38;5;241m=\u001b[39m update_lammps_data(data, update_atom_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.13/site-packages/IPython/core/interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    322\u001b[0m     )\n\u001b[0;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m io_open(file, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'compress_system1/pack_mol.data'"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "import numpy as np\n",
    "from ase import units, Atoms\n",
    "from ase.io import write\n",
    "from ase.io.trajectory import Trajectory\n",
    "from ase.optimize import FIRE\n",
    "from ase.md.velocitydistribution import MaxwellBoltzmannDistribution\n",
    "from loguru import logger\n",
    "import argparse\n",
    "import toml\n",
    "\n",
    "current_script_dir = os.getcwd()\n",
    "parent_dir = os.path.dirname(current_script_dir)\n",
    "sys.path.append(os.path.join(parent_dir, 'src'))\n",
    "\n",
    "from ted.calculators.ReaxFFCalculator import ReaxFFCalculator_LAMMPS\n",
    "from ted.calculators.OPLSAACalculator import OPLSAACalculator_LAMMPS\n",
    "from ted.calculators.partitioned_calc import PartitionedCalculator\n",
    "# from ted.calculators.compress_calc import CompressCalculator\n",
    "from ted.integrators.langevin_nvt import LangevinBAOAB\n",
    "from ted.calculators.lammps_utils import parse_lammps_data_to_ase_atoms, load_lammps_data_0, update_lammps_data\n",
    "from ted.calculators.decorator_utils import Timing\n",
    "\n",
    "parser = argparse.ArgumentParser(description=\"Compress a system using ReaxFF Simulation\")\n",
    "parser.add_argument(\"--solver\", \"-s\", type=str, nargs=\"+\", default=[\"ReaxFF\", \"OPLSAA\"], \n",
    "                    help=\"List of solver names [inner -> outer partitions]\")\n",
    "parser.add_argument(\"--flag\", \"-f\", type=str, default='small1', help=\"system flags\")\n",
    "parser.add_argument(\"--reaxff\", \"-rf\", type=str, default=\"data/reaxff/CHON_reaxff.ffield\", \n",
    "                    help=\"Path to ReaxFF force-field file (lammps format)\")\n",
    "parser.add_argument(\"--oplsaa\", \"-op\", type=str, default=\"data/oplsaa/CHON_oplsaa.ffield\", \n",
    "                    help=\"Path to OPLSAA force-field file (lammps format)\")\n",
    "parser.add_argument(\"--restart\", '-rt', type=str, default=\"\", help=\"Restart from a previous trajectory file\")\n",
    "parser.add_argument(\"--uniqname\", \"-un\", type=str, default=\"\",   help=\"Unique name for the system\")\n",
    "parser.add_argument(\"--partition\", \"-p\", type=str, default=\"\",   help=\"Default partition file name: uniqname.part\")\n",
    "parser.add_argument(\"--neff\", \"-n\", type=str, default=\"\", help=\"Default non-equilibrium force-field file name: uniqname.neff\")\n",
    "parser.add_argument(\"--constraint\", \"-ct\", type=str, default=\"\", help=\"Default constraint definition file name: uniqname.const\")\n",
    "parser.add_argument(\"--thermo\", \"-th\", type=str, default=\"\", help=\"Default thermostat definition file name: uniqname.thermo\")\n",
    "parser.add_argument(\"--coord\", \"-c\", type=str, default=\"\", help=\"Default coordinate file path: uniqname.xyz\")\n",
    "parser.add_argument(\"--input\", \"-i\", type=str, default=\"\", help=\"Default input configuration file path: uniqname.toml\")\n",
    "parser.add_argument(\"--dump\", \"-d\", type=str, default=\"\", help=\"Default dump configuration file path: uniqname.dump\")\n",
    "parser.add_argument(\"--log\", \"-l\", type=str, default=\"\", help=\"Default log file path: uniqname.log\")\n",
    "parser.add_argument(\"--device\", type=str, default=\"cpu\", help=\"Compute device (cpu or cuda)\")\n",
    "args = parser.parse_args()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    config = {\n",
    "        \"global\": {\n",
    "            \"timestep\": 0.5,      # (ase time unit fs?)\n",
    "            \"temperature\": 360.0, # in Kelvin\n",
    "            \"steps\": 10000,\n",
    "            \"min_steps\": 50,\n",
    "            \"interval\": 50,\n",
    "        },\n",
    "    }\n",
    "    if os.path.exists(args.input): config.update(toml.load(args.input))\n",
    "\n",
    "    flag = 'compress_system1'\n",
    "    if os.path.exists(f\"{flag}/run.log\"): os.remove(f\"{flag}/run.log\")        \n",
    "    logger.add(f\"{flag}/run.log\", rotation=\"10 MB\", level=\"INFO\")\n",
    "    logger = logger.bind(name=\"Compress Dynamics (for ReaxFF)\")\n",
    "\n",
    "    # step 1: built ASE atoms\n",
    "    with open(f'{flag}/pack_mol.data', 'r') as f:\n",
    "        data = load_lammps_data_0(f.read())\n",
    "        data = update_lammps_data(data, update_atom_index=True)\n",
    "    atoms = parse_lammps_data_to_ase_atoms(data)\n",
    "    cell = atoms.get_cell()\n",
    "    logger.info(f\"\\nProcessing cell: {cell}\")\n",
    "\n",
    "    min_x = np.min(cell[0, :]); max_x = np.max(cell[0, :])\n",
    "    min_y = np.min(cell[1, :]); max_y = np.max(cell[1, :])\n",
    "    min_z = np.min(cell[2, :]); max_z = np.max(cell[2, :])\n",
    "    logger.info(f\"\\nProcessing cell dimension: {min_x} {max_x} {min_y} {max_y} {min_z} {max_z}\")\n",
    "    atoms.set_cell([max_x - min_x, max_y - min_y, max_z - min_z])\n",
    "    atoms.wrap()\n",
    "    logger.info(f\"\\nProcessing cell after wrap: {atoms.get_cell()}\")\n",
    "    \n",
    "    # logger.info(f\"\\nProcessing Number of atoms: {len(atoms)}\")\n",
    "    # masses = atoms.get_masses()\n",
    "    # logger.info(f\"\\nProcessing masses: {masses}\")\n",
    "    # print('for statistics, here brute force reset H-atoms masses to a larger one! x 6.0')\n",
    "    # for i in range(len(atoms)):\n",
    "    #     if atoms[i].symbol == 'H': masses[i] *= 6.0\n",
    "    # atoms.set_masses(masses)\n",
    "    # logger.info(f'\\nProcessing masses after reset H-atoms: {masses}')\n",
    "\n",
    "    # def init_atom_from_last_frame(atom, fn_traj):\n",
    "    #     with Trajectory(fn_traj, mode='r') as traj:\n",
    "    #         atom.set_positions(traj[-1].get_positions())\n",
    "    #         atom.set_velocities(traj[-1].get_velocities())\n",
    "\n",
    "    # if args.restart:\n",
    "    #     init_atom_from_last_frame(atoms, args.restart)\n",
    "    #     logger.info(f'\\nProcessing initial velocity from restart file!!!')\n",
    "    # else:\n",
    "    #     vel = atoms.get_velocities()\n",
    "    #     logger.info(f'\\nProcessing initial velocity after reset H-atoms: {vel}')\n",
    "    #     MaxwellBoltzmannDistribution(atoms, temperature_K=360.0)\n",
    "\n",
    "    # logger.info(f'\\nProcessing initial velocity after reset H-atoms: {atoms.get_velocities()}')\n",
    "    # logger.info(f'Test atom periodic boundary condition: {atoms.get_pbc()}')\n",
    "\n",
    "    # reax_calc0 = ReaxFFCalculator_LAMMPS(ff_file=f'{flag}/reaxff.ff', tmp_dir=f'{flag}/tmp_reax1')\n",
    "    # comp_calc = CompressCalculator(calc=reax_calc0)\n",
    "    # atoms.calc = comp_calc\n",
    "\n",
    "    # def write_frame(filename: str, atoms: Atoms, append: bool = True):\n",
    "    #     assert filename.endswith('.xyz'), 'filename must end with .xyz'\n",
    "    #     write(filename, atoms, append=append)\n",
    "    #     with Trajectory(filename.replace('.xyz', '.traj'), mode='a') as traj:\n",
    "    #         traj.write(atoms)\n",
    "\n",
    "    # def log_atoms_information(atoms: Atoms, flag: str, iterator):\n",
    "    #     if iterator.nsteps == 0:\n",
    "    #         #                          ===============!===============!===============!===============!===============!\n",
    "    #         logger.info(f\"{flag}   Step  Temperature(K)        Ekin(eV)        Epot(eV)     Volume(A^3)     Rho(g/cm^3)\")\n",
    "    #     masses_true = atoms.get_masses().copy()\n",
    "    #     for i in range(len(atoms)):\n",
    "    #         if atoms[i].symbol == 'H': masses_true[i] = 1.0080 # reset H-atoms masses to 1.0080 amu\n",
    "    #     density = masses_true.sum() / atoms.get_volume() / (0.001*units.kg) * (0.01*units.m)**3\n",
    "    #     logger.info(f\"{flag} {iterator.nsteps:>6d} {atoms.get_temperature():>15.2f} {atoms.get_kinetic_energy():>15.4f} {atoms.get_potential_energy():>15.4f} {atoms.get_volume():>15.2f} {density:>15.4f}\")\n",
    "\n",
    "    # # run minimization here\n",
    "    # if not args.restart:\n",
    "    #     with Timing(\"Minimization\"):\n",
    "    #         total_min_steps = config[\"global\"][\"min_steps\"]\n",
    "    #         logger.info(f\"Starting FIRE minimization for {total_min_steps} steps...\")\n",
    "    #         dyn = FIRE(atoms, logfile=None, trajectory=None)\n",
    "\n",
    "    #         if os.path.exists(f\"{flag}/trajectory_min.xyz\"): os.remove(f\"{flag}/trajectory_min.xyz\")\n",
    "    #         dyn.attach(log_atoms_information, interval=1, atoms=atoms, flag=\"MIN\", iterator=dyn)\n",
    "    #         dyn.attach(write_frame, interval=1, filename=f\"{flag}/trajectory_min.xyz\", atoms=atoms)\n",
    "    #         dyn.run(steps=total_min_steps)\n",
    "    #         logger.info(\"* FIRE MINIMIZATION FINISHED!\")\n",
    "    # else:\n",
    "    #     logger.info(f'\\nProcessing initial velocity from restart file so skip minimization!')\n",
    "\n",
    "    # # run NeFF molecular dynamics here\n",
    "    # with Timing(\"Compress Molecular Dynamics\"):\n",
    "    #     # Initialize integrator\n",
    "    #     integrator = LangevinBAOAB(\n",
    "    #         atoms=atoms,\n",
    "    #         timestep=config[\"global\"][\"timestep\"] * units.fs,  # fs\n",
    "    #         T_tau = 50 * config[\"global\"][\"timestep\"] * units.fs,  # fs\n",
    "    #         temperature_K=config[\"global\"][\"temperature\"],  # K\n",
    "    #         rng=np.random.default_rng(), # no seed!!!\n",
    "    #     )\n",
    "    #     logger.info(f\"test random number: {integrator.rng.random()}\")\n",
    "\n",
    "    #     traj_path = f\"{flag}/trajectory_sample.xyz\"\n",
    "    #     if os.path.exists(traj_path): os.remove(traj_path)\n",
    "    #     if os.path.exists(traj_path.replace('.xyz', '.traj')): os.remove(traj_path.replace('.xyz', '.traj'))\n",
    "    #     if os.path.exists(comp_calc._work_record_file): os.remove(comp_calc._work_record_file)\n",
    "    #     if os.path.exists(comp_calc._bond_record_file): os.remove(comp_calc._bond_record_file)\n",
    "\n",
    "    #     class CustomLogger:\n",
    "    #         def __init__(self, filename: str):\n",
    "    #             self.fileio = open(filename, 'a')\n",
    "    #         def print(self, msg):\n",
    "    #             self.fileio.write(msg + '\\n')\n",
    "    #         def __del__(self):\n",
    "    #             self.fileio.close()\n",
    "\n",
    "    #     if os.path.exists(f'{flag}/neff.log'): os.remove(f'{flag}/neff.log')\n",
    "    #     if os.path.exists(f'{flag}/part.log'): os.remove(f'{flag}/part.log')\n",
    "    #     comp_logger = CustomLogger(filename=f'{flag}/neff.log')\n",
    "    #     part_logger = CustomLogger(filename=f'{flag}/part.log')\n",
    "\n",
    "    #     sample_interval = config[\"global\"][\"interval\"]\n",
    "    #     integrator.attach(write_frame, interval=sample_interval, filename=traj_path, atoms=atoms)\n",
    "    #     # integrator.attach(part_calc.analysis, interval=1, atoms=atoms, iterator=integrator, \n",
    "    #     #     custom_loggor=part_logger)\n",
    "    #     integrator.attach(comp_calc.analysis, interval=1, atoms=atoms, iterator=integrator, \n",
    "    #         custom_loggor=comp_logger, noneq=True) \n",
    "    #     integrator.attach(log_atoms_information, interval=10, atoms=atoms, flag=\"NVT\", iterator=integrator)\n",
    "\n",
    "    #     comp_calc.analysis(atoms=atoms, iterator=integrator,\n",
    "    #         custom_loggor=comp_logger, noneq=True, only_initialize=True) # initialize q & k1 & k2\n",
    "\n",
    "    #     total_steps = config[\"global\"][\"steps\"]\n",
    "    #     integrator.run(total_steps)\n",
    "    #     logger.info(\"* NeFF MD FINISHED!\")\n",
    "\n",
    "    # Timing.report()\n",
    "    # total_steps = config[\"global\"][\"steps\"]\n",
    "    # timestep_in_fs = config[\"global\"][\"timestep\"]\n",
    "    # speed = total_steps / Timing.timers[\"NeFF Molecular Dynamics\"][1] # use wall time\n",
    "    # speed *= timestep_in_fs * 1e-6 * 86400.0  # convert step/s to ns/day\n",
    "    # logger.info(f'NeFF Molecular Dynamics Speed: {speed:.6f} ns / day')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeebe8f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
